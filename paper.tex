%%
%% This is file `sample-authordraft.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `authordraft')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-authordraft.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf,nonacm,review,anonymous]{acmart}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
% \usepackage{amsfonts}
% \usepackage{amssymb}
% \usepackage{amsthm}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
% \usepackage{graphicx}
% \usepackage{fourier}
% \usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx
\DeclareMathOperator*{\argmax}{arg\,max}

\usepackage{mathpartir}
% \usepackage{stmaryrd}
\usepackage{syntax}

\usepackage{lipsum}  
\usepackage{graphicx}               % Necessary to use \scalebox



\usepackage{thmtools} 
\usepackage{thm-restate}

\declaretheorem[name=Theorem,numberwithin=section]{thm}


\def\sectionautorefname{Section}
\def\algorithmautorefname{Algorithm}
\def\tableautorefname{Table}

%% NOTE that a single column version may be required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen,review]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{10.1145/1122445.1122456}

%% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[PLDI SRC '22]{Woodstock '18: ACM Symposium on Neural
%   Gaze Detection}{June 03--05, 2018}{Woodstock, NY}
% \acmBooktitle{Woodstock '18: ACr Symposium on Neural Gaze Detection,
%   June 03--05, 2018, Woodstock, NY}
% \acmPrice{15.00}
% \acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Making the Best of a Bad Situation}
\subtitle{Inferring Random Generators for Numerical Properties with Multi-Armed Bandits}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Joseph W. Cutler}
\email{jwc@seas.upenn.edu}
\orcid{1234-5678-9012}
\affiliation{%
  \institution{University of Pennsylvania}
%   \city{Dublin}
%   \state{Ohio}
  \country{USA}
%   \postcode{43017-6221}
}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Cutler}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  Property-Based Testing in the style of QuickCheck has proven to be a
  very powerful and useful generalization of traditional software testing techniques
  such as unit testing. This power comes at the cost of requiring users to occasionally write \emph{generators}:
  programs which emit random data satisfying the invariants assumed by the program under test. While some work exists
  to derive these generators directly from the invariants in question, this work is mostly focused on highly structured data,
  and often fails to handle the kinds of numerical invariants that occur commonly in systems programming tasks.
  In this extended abstract, we present an approach to inferring generators for a restricted class of numerical properties.
  \vspace{-18px}
\end{abstract}


\maketitle

\section{Motivation}
% \vspace{-3px}
Property-Based Testing (PBT) \cite{qc} is a program testing method which tests
logical properties of functions by randomly generating thousands of inputs, and ensuring that
the the properties hold at each concrete value. Given a property $\forall x. P(x) \implies Q(x)$,
we generate values satisfying $P$, and check that they satisfy $Q$.
While this process is highly automated and requires no user input, users must occasionally write \emph{generators}:
programs which emit random data that satisfies the premise $P$.

Much of the time, this burden can be mitigated by automation, such as when the data structure being generated
is composed entirely of structures that already have generators, or $P$ is described as an inductive
relation \cite{gggir}. However, the case of inferring generators for \emph{numerical} properties---those involving constriants over numbers--- is not well
handled by prior work. Numerical properties appear regularly in
systems programming tasks \cite{???}, where structured data described by inductive invariants is rare, inputs regularly
take the form of pointers and integers, and many function preconditions amount to bounds-checking or ensuring
that certain fields in different structures are related in some way.

In this extended abstract, we develop a method for inferring random generators for a small class of numerical properties akin
to the kind commonly found in systems programming. Because manual generator-writing for numerical properties is especially
tedious, our goal is to infer generators that are comparable to ones that a user might write as a first cut.
The method proceeds by developing a number of generator ``candidates'', expressed in a DSL we call \texttt{ALuck}, described in \autoref{sec:luck}.
These candidates mimic the way that a human might write a generator for numerical preconditions: by randomly choosing values
one variable at a time, constraining subsequent choices by the previous values chosen. In \autoref{sec:sci}, we show how candidates
are chosen from the space of possible \texttt{ALuck} generators.
As we will see, it is sometimes the case that \emph{none} of the candidates are all that good. In this case, we must make the best
of a bad situation, and discover the best candidate among the set. A learning-theoretic method for this is presented in \autoref{sec:bandits}.
Finally, in \autoref{sec:impl}, we describe our implementation of
this algorithm, present benchmarks, and briefly discuss future work.

% JOE:
% We want to be able to do this so we could do PBT for systems-y code!

% Numerical testing is a really bad situation because we can't really leverage any type
% structure to do the work, it's just *constraints*. Even worse, figuring out a way to
% manually generate these from the constraints is very not fun. (Which goes first? etc etc)
% So we do our best to find some candidates and then pick the best. It's not sexy, but it works.

% In this paper, we develop a simple deductive program verifier
% which is backed by PBT instead of SMT. In \autoref{sec:pbt}, we show how PBT can
% be used in place of an SMT solver to do deductive verification. This process is
% conceptually simple, but we will see that it hides a major challenge: generating
% thousands of independent random input sets which satisfy a function's
% precondition is NP-hard. In fact, tackling a small variant of problem is the
% bulk of the content of this report, and its main technical contribution. We give
% a sketch of this contribution in this section. In brief, our technique first
% infers a set of ``candidate" example-generators from the precondition in
% question, and then uses a reinforcement-learning-based online learning algorithm
% to find the best generator among the set.




% \section{PBT, the Generator Problem, and our Approach}
% \label{sec:pbt}
% At the core of all deductive program verifiers is a decision procedure for Hoare
% triples $\{\phi\}\, C \, \{\psi\}$. Such a triple is valid when for all heaps
% $\sigma$ satisfying $\phi$, we have that $\psi$ holds of the heap which results
% after $C$ is run on $\sigma$. In symbols:

% \[
% \forall \sigma. \phi(\sigma) \implies \psi(C(\sigma)) \tag{$\ast$}
% \]

% With traditional SMT-based verifiers, this is decided by compting the weakest
% precondition of $\psi$ with respect to $C$, $\texttt{wp}(C,\psi)$ and using SMT
% to prove that $\phi$ implies it. With property-based random testing, we can skip
% the weakest precondition computation and directly test ($\ast$). PBT tests
% formulae like $\forall x. P(x)$ by randomly generating values $a$ (of a
% specified type), and then evaluating the concrete boolean expression $P(a)$.
% When the property $P$ is an implication $Q \implies R$, as is the case for
% ($\ast$), this is not very effective. Intuitively, we'd like to test that $R$
% holds for a bunch of examples satisfying $Q$, but what actually ends up
% happening is that the vast majority of our random examples satisfy $Q \implies
% R$ simply because they don't satisfy $Q(x)$. To fix this, PBT relies on
% \textit{user-written} generators which generate values \textit{satisfying $Q$},
% and then checking that $R$ holds.

% While 
% In terms of ($\ast$), this means that a user of a verifier backed by PBT would
% have to provide programs which generate random heaps $\sigma$ to satisfy the
% preconditions of every function they plan to test. This is labor-intensive,
% error prone, and diminishes the benefits of PBT over SMT-based verification. To
% make the former practical, we need to \textit{automatically} create generators
% from the ``source code" of a specification. Unfortunately, this problem is
% NP-Hard in even simple cases. If we limit ourselves to preconditions $\phi$
% which consist only of arithmetic constraints (which we will in fact do), the
% problem of generating hundreds of sets of inputs which satisfy $\phi$ is as hard
% as generating \textit{one} set of inputs, which is equivalent to SMT solving.

% In the rest of this report, we will focus in on this generation problem, and
% present a solution to a specific instance of it. The main cause of the generator
% problem described above is that propositions are \textit{declarative}: they
% simply state what must hold in order for them to be satisfied, and provide no
% instructions on how to generate values which satisfy them. In classical PBT, the
% user is required to write \textit{generators} which are programs that emit
% random values satisfying a property. Ideally, we would like to automatically
% translate declarative propositions into generators, but as stated earlier, this
% is arbitrarily hard. Instead, the core of our approach is a translation of
% propositions into a large set of \textit{potentially failing} generators. By
% relaxing the problem from inferring one \textit{perfect} generator to a few
% carefully-chosen generators of unknown (but hopefully high) quality, we make the
% problem tractable. Empirically, it seems that among a large enough set of these
% automatically-created generator candidates, there is often one which
% approximates a generator which a human would have written for the same
% proposition. With this in mind, we can then run an online learning algorithm to
% learn which among the candidates is the best, while simultaneously generating a
% sequence of random inputs for testing purposes.

\section{Syntax of Propositions and \texttt{ALuck}}
\label{sec:luck}

The syntax of propositions that we handle are shown in
\autoref{fig:precond-syntax-and-aluck}. These are conjunctions and negations of
arithmetical equalities and inequalities with variables, which range over
the arguments of the function under test. The allowable expressions in these inequalities are
essentially multi-linear functions, where each variable occurs with degree at
most one. While this form is restrictive, we have found empirically that this covers
a wide range of preconditions in systems verification. Moreover, there
appears to be no inherent difficulty to extending the technique to handle
other numerical operators (div, mod), and constraints over structured types like lists: we present the algorithm as-is to
simplify the discussion.

\begin{figure}
\vspace{-10px}
\caption{Syntax of Propositions and Generator Scripts}
\label{fig:precond-syntax-and-aluck}
\scalebox{0.8}{\parbox{\linewidth}{%
$$
\begin{array}{llll}
\text{Expressions} & e & ::= & x \; | \; e + e \; | \; -e \;|\; e*e\\
\text{Relations} & R & ::= & = \;|\; \leq \;|\; <\\
\text{Propositions} & P & ::= & P \wedge P \;|\; e R e\\
\end{array}
$$
}}

\scalebox{0.8}{\parbox{\linewidth}{%
$$
\begin{array}{llll}
\text{Generator Actions} & a & ::= & !x \;|\; e R e\\
\text{Generator Scripts} & s & ::= & [] \;|\; a \, :: \, s\\
\end{array}
$$
}}
\vspace{-15px}
\end{figure}

To make the generator inference problem tractable, we fix the
syntactic form of the generators. Our generators are written
in a language called \texttt{ALuck} (for \textit{arithmetic} \texttt{Luck})
inspired by \texttt{Luck} \cite{luck}, a domain-specific language for writing
generators. Generators written \texttt{ALuck} run by sequentially \textit{constraining} and
\textit{concretizing} variables. Every variable in an \texttt{ALuck} generator
begins as a symbolic variable. Constraints over these variables are then added.
Variables can then be concretized, wherein they are replaced by a random value
satisfying the constraints on that variable that have been accumulated thusfar.
The final result of the generator is a map from variables to their (randomly)
chosen values.

More concretely, generators in \texttt{ALuck} are sequences of ``concretize"
operations, written $!x$, and ``constrain" operations, written simply as the
constraint to be added. This syntax is shown in
\autoref{fig:precond-syntax-and-aluck}. These sequences are then evaluated from left to
right while maintaining a pair of mappings: one from concretized variables to
their values, and the other from yet-unconcretized variables to the set of
constraints that have accumulated on them.  When a ``constrain" operation $c$ is
encountered, the constraint $c$ is added to the constraint sets of all of the
variables it mentions. If a constraint mentions no variables, it is checked for
valdity: if the constraint is not valid, the generator fails.

When a ``concretize" operation $!x$ is encountered, a value is randomly sampled from
the uniform distribution on the set of possible values\footnote{ Because
integers are bounded by machine word lengths, the ``uniform distribution" does
make sense here, even for unconstrained variables.  } denoted by the constraints
on $x$. This semantics is shown in \autoref{fig:aluck-semantics}, where the
judgment $V,C \vdash s \Downarrow V',C'$ means that the script $s$ evaluates
under concretized-variable-map $V$ and constraint map $C$, and returns updated
variable and constraint maps $V'$ and $C'$. We note that this semantics is partial,
as generators can fail when attempting to concretize a variable whose constraints are unsatisfiable.
This is crucial: different generators for the same property can fail more or
less often, and we would like to infer generators which fail infrequently.

To make the sampling step tractable, we enforce that our \texttt{ALuck} programs be
``well-concretized": when $!x$ occurs, all variables which occur
in constraints with $x$ must already have been concretized.

% To give some intuition about how these generator scripts work, we consider
% running the example script $s = [0 \leq x, !x, x \leq y, !y]$, which is a
% generator script for $P(x,y) = 0\leq x \leq y$. When we run $s$, the constraint
% $0 \leq x$ is added to $x$. Next, $x$ is concretized: a value $a$ is sampled
% from $\mathcal{U}\left[0,2^{64}-1\right]$. Then, the constraint $a \leq y$ is
% added to $y$. Finally, a value $b$ is sampled from
% $\mathcal{U}\left[a,2^{64}-1\right]$, and the result $\{x \mapsto a, y \mapsto
% b\}$ is returned.

% It is crucial to note that generators can fail. For example, the generator
% $[!x,!z, x \leq y \leq z, !y]$ will fail if the generated $x$ and $z$ are such
% that $z < x$:  the sample domain for $y$ will be empty. Some generators like
% this one fail much all the time, and some such as the generator $s$ above never
% fail.

\begin{figure}
\vspace{-10px}
\caption{Generation Semantics}
\label{fig:aluck-semantics}

\scalebox{0.75}{\parbox{\linewidth}{%
\begin{mathpar}
\inferrule{v \sim \mathcal{U}\left(\llbracket C(x)\rrbracket\right)\\ V\{x \mapsto v\},C \vdash s \Downarrow V',C'}{V,C \vdash !x :: s \Downarrow V',C'}

\inferrule{C'(x) = C(x) \cup \{c\} \\ V,C' \vdash s \Downarrow V',C'' }{V,C \vdash c(x) :: s \Downarrow V',C''}
\hspace{5px}
\inferrule{V \vDash c \\ V,C \vdash s \Downarrow V',C'}{V,C \vdash c :: s \Downarrow V',C'}
\end{mathpar}
}}
\vspace{-15px}
\end{figure}

\section{Generator Candidate Inference}
\label{sec:sci}
The first step in our algorithm is to infer a set of generators from a given
predicate. We begin by noting that every ordering of the variables in a property
immediately determines a well-concretized generator:
this procedure is shown in the Appendix in \autoref{alg:fixed-ordering}.
In essence, the procedure works by placing all of the constraints that could possibly
appear before a concretization immediately before it.

Because of this, to infer generators for a property $P$, it suffices to
generate orderings of its variables. Unfortunately, for a property $P$ with
$n$ free variables, there are $n!$ such orderings: a very large search space.
Fortunately, we can prune this search space by only looking for ``relevant"
orderings. If some variables are not related to others, the well-concretization
condition won't care the relative order in which they're generated.

% To illustrate, consider the property $x \leq y \wedge u \leq v$.
% There are $24$ different variable orderings on $4$ variables, but there are
% really only four useful concretization orders: the two possible orders of $x$
% and $y$, combined with the two possible orders of $u$ and $v$. Because there are
% no interactions between $x$ and $u$ or $y$ and $v$, the two orderings $x,u,y,v$
% and $x,y,u,v$ will give the same generator. This quotienting allows us to shrink
% the space of orderings significantly.

To operationalize this insight, we build a graph $G(P)$ whose nodes are variables
with an edge $(x,y)$ when $x$ and $y$ both occur in one of the conjuncts of $P$. In
this graph, ``unrelated'' variables live in different connected components.
Then, to generate a concretization ordering, we depth-first search $G(P)$, randomly
choosing the next neighbor to explore,
and list variables in the order that they're visited in the graph.
Since different connected components are listed separately, unrelated variables
will not 
The fact that related variables lie in separate connected components means
that 
% we create an undirected graph from a proposition to
% encode the important inter-relationships that a concretization order should
% capture.

% Pseudocode for this is shown in \autoref{alg:generate-ordering}.

% \begin{algorithm}
%     \caption{Generate a Random Concretization Ordering}
%     \label{alg:generate-ordering}
%     \begin{algorithmic}
%       \Function{randomConcr}{$P$}
%       \State $G \gets G(P)$ 
%       \State $X \gets \{\}$
%       \State $S \gets $ shuffle(V($G$))
%       \State $xs \gets []$
      
%       \While{$S \neq []$}
%        \State $x \gets $ Pop($S$)
%        \If{$x \notin X$}
%          \State $X \gets X \cup \{x\}$
%          \State $xs \gets $ append($xs$,$[x]$)
%          \State $S \gets $ append(shuffle(N($x$)),$S$)
%        \EndIf

%       \EndWhile
      
%       \Return $xs$
      
%       \EndFunction
%     \end{algorithmic}
% \end{algorithm}

To generate our set of generator candidates, we repeatedly run this function.
This may give repeated generators, and so we filter the result for uniqueness.
The number of generators in our set requires a careful
balance. Too few and the set may not contain a generator which succeeds often
enough to rapidly generate our desired number of unique inputs. Too many and the
learning algorithm will converge too slowly to the best generator in the set.
Empirically, we have found that $n^2$ (where $n$ is the number of variables in
$P$) is a number of generators to take.

\section{Generator Learning with Bandits Algorithms}
\label{sec:bandits}
With our bag of generators in hand, we now need to find the best one. The
approach we take will be inspired by the Multi-Armed Bandits
\cite{gittins1979bandit} problem from the theory of reinforcement learning. In short, the multi armed
bandits problem describes a situation where an algorithm is repeatedly presented
a fixed set of choices. Each choice gives a different (random) reward, and the
goal of the game is to maximize the total reward. Solving this optimization problem
online is too difficult in an adversarial setting, so algorithms for the multi-armed
bandits problem aim to instead minimize \emph{regret}: how much worse their total reward
was than the best possible total reward in hindsight. To achieve this, bandits algorithms
learn which actions have historically given more reward, and play those more frequently.
In our setting, the ``choices" are our
generator candidates, and the rewards are given by success or failure of a
generator to yield a value. Under this analogy, an algorithm for the Multi-Armed
Bandits problem will let us learn which generators give the best results
\textit{while simultaneously} generating a stream of valid inputs for the
function.



The algorithm we will use is called UCB1 \cite{auer2002finite}. While more sophisticated
bandits algorithms exist, this one is sufficient for our purposes. When given a list of generators
$g_1,\dots g_k$ and a number of rounds $T$ to run for, UCB1 runs the generators $g_i$ in a way that attempts
to learn which generator succeds the most frequently, while also attempting to not waste time by running
failing generators too much. In the end, UCB1 emits the $m \leq T$ successfully-generated values over the course of its run.
The main upshot is that the ratio success ratio $\frac{m}{T}$ of this derived generator should, in the limit,
be no worse than the \emph{best} generator the algorithm was given. 
% UCB1 achieves a
% regret bound of $O(\sqrt{KT\log K})$. While algorithms are known which achieve
% $O(\sqrt{KT})$ regret, UCB1 is simple to implement and understand, and performs
% more than well enough for our setting. In \autoref{alg:ucb1}, we present the
% UCB1 algorithm, modified for use in property-based testing. The algorithm takes
% generator candidates $g_1,\dots g_k$, the property $P$, a number of rounds to
% run for $T$, and returns a list of generated values satisfying $P$.
\begin{restatable}{thm}{regretthm}
Fix a property $P$ and generators $g_1,\dots,g_K$, where $g_i$ succeeds with probability at least $p_i$. Then,
\vspace{-2px}
\[
\lim_{T \to \infty} \mathbb{E}\left[\frac{1}{T}\left|\texttt{ucb1}(g_1,\dots,g_K,P,T)\right|\right] \geq \max_i p_i
\]
\end{restatable}
% Intuitively, this theorem justifies our intuition that the ucb1 algorithm
% ``finds the best generator". As the number of rounds gets large, the ratio of
% the number of valid inputs generated by \texttt{ucb1} to the number of rounds is
% no worse than the success probability of the best generator. 
In other words, with high probability
% \footnote{One could do an
% analysis using Chebyshev's inequality to bound the difference between the
% empirical frequency of the sequence and its mean.}
, the stream of values
emitted by an ``infinite run" of UCB1 acts like a $(\max_i p_i)$-good
generator for $P$.


\section{Implementation, Results, and Future Work}
\label{sec:impl}

I have implemented the generator inference algorithm described in this abstract,
as well as a deductive program verifier (a la Dafny or Frama-C \cite{??}) for the
\texttt{IMP} language which uses these generators as a verification backend.
The code is available \href{https://github.com/jdublu10/triple-testing}{here}.

% Because the generator inference algorithm implemented by the prototype is the
% first of its kind, there are no existing tools we can compare it to in a
% benchmark. Instead, we simply present our results as a table
% (\autoref{tab:data}) of data about runs of the algorithm on different inputs. We
% leave it to the reader to decide if these results are impressive.

In \autoref{tab:data}, we show the results for some trials of our algorithm. In
each trial, we run the generration algorithm on the specified constraint five
times for $T = 1000$ iterations. 
% $K$ is the average number of unique scripts
% discovered by the random DFS, Rejected is the average number of failed generator
% samples that happen during the runs, and Unique is the average number of unique
% input sets generated. In all cases, the generation takes less than 1ms of wall
% clock time. Integers are generated in the range $[-10000,10000]$ instead of the full integer
% range.

In \autoref{tab:data-selected}, we present selected results: a larger table
is available in the Appendix. The largest issue is the performance
differences between the runs on the proposition $0 \leq x \leq y \leq 100$ with
and without explicitly including the implicand $x \leq 100$.
The ``best" generator for the proposition without it samples an
arbitrary $x \geq 0$, which is very unlikely to leave room for some $y$
satisfying $x \leq y \leq 100$. Including the added constraint ensures that we leave space
with our initial choice of $x$.

% Further, we have only scratched the surface of reinforcement learning
% in \autoref{alg:ucb1}. Further tricks such as a probabilistic policy and
% dropping particularly bad generators could lead to faster convergence of the
% learner.

\begin{table}[h]
\label{tab:data-selected}
\centering
\scalebox{0.8}{\parbox{\linewidth}{%
\begin{tabular}{|l|l|l|l|l|}
\hline
Constraint & $K$ & $R$ & $U$ \\ \hline
    %  $0 \leq x \leq y \leq 100 \wedge x \leq 100$ & $2$ & $11$ & $831$ \\ \hline
     $x = y + z \wedge x \geq y \wedge x,y,z \geq 0$      &   $4$  &    $48.6$      &    $951.4$    \\ \hline
     $0 \leq x \leq y \leq 100$ & $2$ & $993.4$ & $6.6$ \\ \hline
     $0 \leq x \leq y \leq 100 \wedge x \leq 100$ & $2$ & $11$ & $831$ \\ \hline
     $x - y \leq 5 \wedge x - y \leq 10 \wedge y - z \leq 2$ & $3.8$ & $26.2$ & $831$ \\ \hline
\end{tabular}
\caption{Selected Results. $K$ = average number of unique scripts, $R$ = number of failed draws, $U$ = number of unique values generated}
}}
\end{table}

\clearpage
\bibliographystyle{plain}
\bibliography{refs}

\clearpage
\appendix
\section*{Appendix}

\begin{center}
\begin{table}[h]
\label{tab:data-full}
\centering
\scalebox{0.8}{\parbox{\linewidth}{%
\begin{tabular}{|l|l|l|l|l|}
\hline
Constraint & $K$ & $R$ & $U$ \\ \hline
     $0 \leq x \leq y \leq 100 \wedge x \leq 100$ & $2$ & $11$ & $831$ \\ \hline
     $x = y + z \wedge x,y,z \geq 0$      &   $5$   &    $506$      &     $494$   \\ \hline
     $x = y + z \wedge x \geq y \wedge x,y,z \geq 0$      &   $4$  &    $48.6$      &    $951.4$    \\ \hline
     $0 \leq x \leq y $  &  $2$   &  $24.6$   &       $975.4$       \\ \hline
     $0 \leq x \leq y \leq 100$ & $2$ & $993.4$ & $6.6$ \\ \hline
     $0 \leq x \leq y \leq 100 \wedge x \leq 100$ & $2$ & $11$ & $831$ \\ \hline
     $x - y \leq 5 \wedge x - y \leq 10 \wedge y - z \leq 2$ & $3.8$ & $26.2$ & $831$ \\ \hline
\end{tabular}
\caption{Full Results}
}}
\end{table}
\end{center}
\noindent\rule{0.5\textwidth}{1pt}

\begin{algorithm}
    \caption{Generator from an ordering}
    \label{alg:fixed-ordering}
    \begin{algorithmic}
      \Function{constructGenerator}{$xs$,$P$}
       \State $P_{const} \gets$ conjuncts in $P$ mentioning only one variable
       \State $P \gets$ $P$ without $P_{const}$
       \State $s \gets P_{const}$ 
       \State $ys \gets []$ 
       \For{$x \in xs$}
         \State $P' \gets$ conjuncts in $P$ mentioning $x$ and variables in $ys$
         \State $s \gets$ append($s$,append($c'$,$!x$))
         \State $P \gets$ $P$ without $P'$
         \State $ys \gets$ append($ys$,$x$)
       \EndFor
       \State $s \gets$ append($s$,$P$)
       
       \Return $s$
      \EndFunction
    \end{algorithmic}
\end{algorithm}



\subsection*{Bandits and UCB1}
The Multi-Armed Bandits problem is
described as the following repeated game: at each round $t$, the player plays an
action $a_t \in [K]$, and receives a reward $X_{{a_t},t}$, which is a
$\{0,1\}$-valued random variable. The random variables $X_{i,t}$ are IID for
fixed $i$, and independent for fixed $t$. We write the mean of the $i$th reward
variable (for all $t$) $\mu_i$. The goal of the game is to maximize one's
reward, and so the goal of a bandits learning algorithm is to learn an adaptive
policy, which takes a history of play up until state $t$ (all actions $a_{t'}$
and received rewards $X_{a_{t'},t'}$ for $t' < t$), and produces a new action
$a_t$. The metric by which we compare bandits algorthms is \textit{regret}: how
much worse they do than the best policy in hindsight.

\begin{definition}[Regret]
Define $i_\star = \argmax_i \mu_i$, and write $\mu_\star = \mu_{i_\star}$. The regret $R(A)$ of an algorithm $A$ over $T$ rounds is defined as
$$
R(A) = T\mu_\star - \mathbb{E}\left[\sum_{t=1}^T X_{A(t),t}\right]
$$
\end{definition}

\begin{algorithm}
    \caption{Learn a Generator}
    \label{alg:ucb1}
    \begin{algorithmic}
      \Function{ucb1}{generators $g_1,\dots,g_K$, property $P$, rounds $T$}
      \For{$i = 1...K$}
      \State $x_i \gets $ sample($g_i$)
      \State $\hat{\mu}_i \gets$ $1$ if $P(x_i)$, $0$ otherwise
      \State $n_i \gets 1$

      \EndFor
      \State $X \gets []$
      \For{$t = 1...T$}
        \State $j \gets \argmax_i \hat{\mu}_i + \sqrt{\frac{2\log t}{n_i}}$
        \State $x \gets$ sample($g_j$)
        \If{$P(x)$}
          \State $r_t \gets 1$
          \State $X \gets$ snoc($X$,$x$)
        \Else
          \State $r_t \gets 0$
        \EndIf
        \State $\hat{\mu}_j \gets \hat{\mu}_j + r_t$
        \State $n_j \gets n_j + 1$
      \EndFor
      \EndFunction
    \end{algorithmic}
\end{algorithm}



\regretthm*
\begin{proof}
We begin by noting that $r_t = 1$ in an iteration if and only if an element is added to the output list in stage $t$. Therefore, the length of the output $\left|\texttt{ucb1}(g_1,\dots,g_K,P,T)\right|$ is precisely the sum of the ($\{0,1\}$-valued) $r_t$, $\sum_{t=1}^T r_t$. In the notation of the bandit problem, $r_t$ is the (revealed) value of the random variable $X_{A(t),t}$, and so 

$$\mathbb{E}\left[\left|\texttt{ucb1}(g_1,\dots,g_K,P,T)\right|\right] = \mathbb{E}\left[\sum_{t=1}^T r_t\right] = \mathbb{E}\left[\sum_{t=1}^T X_{A(t),t}\right]$$.

But then by the definition of regret,

$$
\mathbb{E}\left[\sum_{t=1}^T X_{A(t),t}\right] = T\mu_{\star} - R(A)
$$

Dividing through by $T$, using the regret bound for UCB1, and the fact that $p_i \geq \mu_i$, we have that:
\begin{align*}
\mathbb{E}\left[\frac{1}{T}\sum_{t=1}^T X_{A(t),t}\right] &= \mu_\star - \frac{R(A)}{T}\\
&\geq \mu_{\star} - O\left(\sqrt{\frac{K\log K}{T}}\right)\\
&\geq \max_i p_i - O\left(\sqrt{\frac{K\log K}{T}}\right)
\end{align*}
which approaches $\max_i p_i$ as $T \to \infty$.
\end{proof}



\end{document}
\endinput
%%
%% End of file `sample-authordraft.tex'.

